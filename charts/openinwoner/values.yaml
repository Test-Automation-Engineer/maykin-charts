global:
  settings:
    # -- Global databasehost, overrides setting.database.host
    databaseHost: ""

tags:
  redis: true
  elasticsearch: true

replicaCount: 1

image:
  repository: maykinmedia/open-inwoner
  pullPolicy: IfNotPresent
  # -- uses .Chart.AppVersion by default
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""
  automountServiceAccountToken: true

podAnnotations: {}

podLabels: {}

podSecurityContext:
  fsGroup: 1000

securityContext:
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: false
  runAsNonRoot: true
  runAsUser: 1000

livenessProbe:
  initialDelaySeconds: 60
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 6
  successThreshold: 1

readinessProbe:
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 6
  successThreshold: 1

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  className: ""
  # -- ingress hosts
  hosts: []
  #  - host: openinwoner.gemeente.nl
  #    paths:
  #      - path: /
  #        pathType: ImplementationSpecific
  tls: []
  #  - secretName: openinwoner-tls
  #    hosts:
  #      - openinwoner.gemeente.nl

extraIngress: []
# e.g:
# extraIngress:
#  - name: openinwoner-azuregateway
#    annotations:
#      appgw.ingress.kubernetes.io/ssl-redirect: "true"
#    className: azure-application-gateway
#    hosts:
#      - host: openinwoner.gemeente.nl
#        paths:
#          - path: /
#            pathType: ImplementationSpecific
#            servicename: openklant
#            portNumber: 8000
#    tls:
#      - secretName: openinwoner-tls
#        hosts:
#          - "openinwoner.gemeente.nl"

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 1000m
  #   memory: 1Gi
  # requests:
  #   cpu: 250m
  #   memory: 512Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

pdb:
  create: false
  minAvailable: 1
  maxUnavailable: ""

nodeSelector: {}

tolerations: []

affinity: {}

persistence:
  enabled: true
  size: 1Gi
  storageClassName: ""
  existingClaim: null
  mediaMountSubpath: openinwoner/media
  privateMediaMountSubpath: openinwoner/private_media

# Existing Secret must be defined for AzureVaultSecret to work
existingSecret: null

# This will create an AzureVaultSecret object in k8s, only Multi Key Value Secret are supported by this chart
# ref: https://akv2k8s.io/tutorials/sync/4-multi-key-value-secret/ https://learn.microsoft.com/en-us/azure/key-vault/secrets/multiline-secrets
# Using this feature requires you to define existingSecret
azureVaultSecret:
  # The name of the Azure Key Vault, setting this will create the AzureVaultSecret
  vaultName: null
  # The name of the Multi Key Value Secret
  objectName: ""
  # Make sure this matches the content of the secret, can be either 'application/x-json' or 'application/x-yaml'
  contentType: ""
  # You must set .Values.existingSecret
  secretName: "{{ .Values.existingSecret }}"

# -- Array with extra environment variables to add
extraEnvVars: []
# e.g:
# extraEnvVars:
#   - name: FOO
#     value: "bar"

# -- Optionally specify extra list of additional volumes
extraVolumes: []
# e.g:
# extraVolumes:
#   - name: verify-certs
#     configMap:
#       name: verify-certs

# -- Optionally specify extra list of additional volumeMounts
extraVolumeMounts: []
# e.g:
# extraVolumeMounts:
#  - name: verify-certs
#    mountPath: /etc/ssl/certs/extra-certs/

# -- Extra objects to deploy (value evaluated as a template)
extraDeploy: []

settings:
  allowedHosts: ""
  djangoSettingsModule: open_inwoner.conf.docker

  # -- Will load all fixtures in /app/src/open_inwoner/conf/fixtures/*.json
  loadFixtures: false

  # -- Elasticsearch hostname, only required when tags.elasticsearch is false
  elasticSearchHost: ""

  # -- Generate secret key at https://djecrety.ir/
  secretKey: ""

  environment: null

  database:
    host: ""
    port: 5432
    name: ""
    username: ""
    password: ""
    sslmode: prefer

  email:
    host: localhost
    port: 25
    username: ""
    password: ""
    useTLS: false
    defaultFrom: ""

  elasticapm:
    url: ""
    token: ""

  smsgateway:
    # -- For example "open_inwoner.accounts.gateways.MessageBird"
    backend: ""
    apikey: ""

  brpVersion: ""

  digidMock: ""
  eherkenningMock: ""

  sentry:
    dsn: ""

  cache:
    # -- Sets 'CACHE_DEFAULT' var, only required when tags.redis is false
    default: ""
    # -- Sets 'CACHE_AXES' var, only required when tags.redis is false
    axes: ""
    # When not using the redis subcharts you can set them manually like this:
    # default: myredisserver:6379/0
    # axes: myredisserver:6379/0

  # Celery cache settings, when the redis subchart is enabled these settings will be ignored and caching will default to the redis subchart services
  celery:
    # e.g.:
    # brokerUrl: redis://openforms-redis-master:6379/1
    # resultBackend: redis://openforms-redis-master:6379/1
    brokerUrl: ""
    resultBackend: ""
    logLevel: debug

  isHttps: true

  debug: false

  uwsgi:
    master: false
    threads: ""
    processes: ""
    maxRequests: ""
    harakiri: ""

  # -- Runs a init container that will run /app/src/manage.py search_index --rebuild -f. You might want to enable this one time for new deployments if you want to prevent 500 errors when using the search function
  searchInexInitContainer: false

worker:
  replicaCount: 1
  concurrency: 4
  podLabels: {}
  resources: {}
  # Defaults to 60s
  maxWorkerLivenessDelta: ""
  livenessProbe:
    exec:
      command:
        - python
        - /app/bin/check_celery_worker_liveness.py
    initialDelaySeconds: 60
    # Periodeseconds should not exceed maxWorkerLivenessDelta
    periodSeconds: 50
    timeoutSeconds: 5
    failureThreshold: 10
    successThreshold: 1
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80

beat:
  replicaCount: 1
  podLabels: {}
  resources: {}

celeryMonitor:
  replicaCount: 1
  podLabels: {}
  resources: {}

nginx:
  image:
    repository: nginxinc/nginx-unprivileged
    pullPolicy: IfNotPresent
    tag: stable
  config:
    clientMaxBodySize: 10M
    # -- Configure nginx basic authentication, only use if you are unable to set it on your ingress controller
    basicAuth:
      # -- Enables nginx basic password authentication
      enabled: false
      # -- You need to generate the encrypted basic auth password yourself
      users: |-
        usernameexample:$apr1$5QwE2Ysc$ycRucgmLt0iQMMxcnu4CA/
  service:
    type: ClusterIP
    port: 80
    annotations: {}
  replicaCount: 1
  podLabels: {}
  securityContext:
    capabilities:
      drop:
      - ALL
    readOnlyRootFilesystem: false
    runAsNonRoot: true
    runAsUser: 101
  autoscaling:
    enabled: false
  livenessProbe:
    initialDelaySeconds: 60
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
    successThreshold: 1
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
    successThreshold: 1
  resources: {}


##################
# Redis subchart #
##################

redis:
  architecture: standalone
  auth:
    enabled: false
  master:
    persistence:
      enabled: true
      size: 8Gi
      storageClass: ""
    resources:
      requests:
        cpu: 10m
        memory: 20Mi

##########################
# elasticsearch subchart #
##########################

elasticsearch:
  master:
    masterOnly: true
    replicaCount: 1
    persistence:
      enabled: true
      storageClass: ""
      size: "8Gi"
    resources:
      limits: {}
      requests:
        cpu: 25m
        memory: 256Mi
  data:
    replicaCount: 1
    persistence:
      enabled: true
      storageClass: ""
      size: 8Gi
  coordinating:
    replicaCount: 1
  ingest:
    enabled: false
